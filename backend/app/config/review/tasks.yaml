extract_blueprint_task:
  description: >
    PHASE 1 (VALIDATE): Inspect {design_doc}. If it lacks at least 2 components, data flows, or a clear objective, set 'is_valid' to False and list the missing items in 'validation_errors'. STOP HERE if invalid.

    PHASE 2 (EXTRACT): If valid, analyze the design document provided in the input. Your analysis must follow these Core Directives:
    1. Literal Architecture: Classify the system exactly as described (e.g., if it says Monolith, it is a Monolith).
    2. State Analysis: Identify if storage is local (stateful) or external (stateless).
    3. Protocol Extraction: Trace every line in Mermaid diagrams. If no protocol is mentioned, mark as 'unspecified'.
    4. No Improvements: Purely describe the current state; do not suggest fixes.
    
    Instructions for Mermaid Parsing:
    - Identify all nodes (e.g., [FE], [BE], [(DB)]).
    - Trace the direction and labels of every arrow.
    
    Design Document to process:
    {design_doc}
  expected_output: >
    A strictly formatted JSON object containing:
    - system_identity (name, style, deployment_target, goals)
    - component_registry (list of components with technology, hosting, and statefulness)
    - interaction_map (source-to-destination mapping with protocols and nature)
    - technical_constraints (traffic, performance, and security requirements)
    - omission_report (discrepancies between text and diagram)
  agent: blueprint_specialist

performance_review_task:
  description: >
    Perform a deep-dive performance audit using the provided System Blueprint. Your analysis must focus on three technical "Traps":
    1. The Event Loop Trap: Analyze CPU-bound work (like ReportGen) on the main thread.
    2. The Statefulness Trap: Evaluate dependencies on "Local Server Disk" that prevent horizontal scaling.
    3. The SPOF Trap: Identify components without redundancy (e.g., single MySQL instances).
    
    CRITICAL: If the blueprint context is empty or indicates a validation failure,
    simply output "SKIPPED: Invalid input." and do not perform the analysis.

    Quantify risks using technical terminology (e.g., IOPS Saturation, Blocking Operations). Analyze concurrency impacts specifically for "Peak Traffic" scenarios.
      
  expected_output: >
    A JSON object containing:
    - performance_audit_summary: A high-level overview of system readiness.
    - bottlenecks: List of specific issues with type, component, observation, impact_at_scale, severity, and technical_remediation.
    - scalability_blockers: Specific reasons why horizontal scaling or Load Balancers cannot be implemented.
    - reliability_score: A 0-100 score with a detailed technical justification.
  async_execution: true
  agent: performance_specialist

security_review_task:
  description: >
    Perform an aggressive security audit of the provided System Blueprint using the STRIDE framework (Spoofing, Tampering, Repudiation, Information 
    Disclosure, Denial of Service, Elevation of Privilege).
    
    CRITICAL: If the blueprint context is empty or indicates a validation failure,
    simply output "SKIPPED: Invalid input." and do not perform the analysis.

    Analytical Directives:
    1. Evidence-Based: Link every risk to a specific component or interaction map key.
    2. Broken Auth: Closely inspect /reports/download constraints.
    3. Protocol Analysis: Treat 'Port 80' or 'unspecified' as Critical Disclosure risks.
    4. Stateful Risks: Analyze local shell access risks for 'Local Server Disk' hosting.
    
    Refer to the omission_report to identify missing security-critical controls.
      
  expected_output: >
    A JSON object containing:
    - threat_model_summary: High-level risk assessment.
    - vulnerabilities: List of threats with STRIDE category, OWASP mapping, 
      attack vector, and mitigation strategy.
    - trust_boundary_violations: List of areas where data moves across security zones.
    - missing_security_controls: Critical omissions identified from the blueprint.
  async_execution: true
  agent: security_specialist

final_review_task:
  description: >
    Your input is the collection of reports generated by the previous agents: the System Librarian (Blueprint), the SRE (Performance), and the Security Architect.
    
    CRITICAL DATA GATE:
    Verify if the Blueprint data is valid. If the document was unreadable or violates basic architectural standards, set 'data_available' to false 
    and explain the failure in 'deep_dive'.
    
    Analytical Directives:
    1. De-duplication: Compare findings across SRE and Security reports. If both flag the same component (e.g., 'Single Instance DB'), merge them into a 
       single 'Critical Structural Flaw'.
    2. Prioritization: Rank by impact. Security P1 items always take precedence.
    3. Business Translation: Ensure the 'finding' in the audit table is understandable by a CTO. (e.g., instead of 'No Load Balancer', use 
       'Single Point of Failure impacting Service Continuity').
  
  expected_output: >
    A final ReviewReport (JSON). Ensure 'data_available' reflects the state of the input doc. All fields in the Pydantic model must be populated.
  agent: chief_architect
